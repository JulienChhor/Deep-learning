{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "import skvideo\n",
    "import skvideo.io\n",
    "import cv2\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential,model_from_json\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.optimizers import sgd, adam\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MiniProject #3: Deep Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
    "\n",
    "\\begin{equation*}\n",
    "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
    "\\end{equation*}\n",
    "\n",
    "where: \n",
    "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "We note the $Q$-function:\n",
    "\n",
    "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "Thus, the optimal Q function is:\n",
    "\\begin{equation*}\n",
    "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The environment, the agent and the game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def act(self, act):\n",
    "        \"\"\"\n",
    "        One can act on the environment and obtain its reaction:\n",
    "        - the new state\n",
    "        - the reward of the new state\n",
    "        - should we continue the game?\n",
    "\n",
    "        :return: state, reward, game_over\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reinitialize the environment to a random state and returns\n",
    "        the original state\n",
    "\n",
    "        :return: state\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def draw(self):\n",
    "        \"\"\"\n",
    "        Visualize in the console or graphically the current state\n",
    "        \"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class Environment(object):\n",
    "#    def __init__(self, states, rewards, transitions, currentState,T,mu):\n",
    "#        self.states = states # size : N\n",
    "#        self.rew = rewards\n",
    "#        self.P = transitions # transition matrix : size A times N times N where A = size of action space\n",
    "#        self.t = 0 # current step\n",
    "#        self.currentState = currentState\n",
    "#        self.maxStep = T \n",
    "#        self.mu = mu #initial probability distribution\n",
    "#\n",
    "#    def act(self, act):\n",
    "#        s = self.currentState\n",
    "#        trans = self.P[s][act]\n",
    "#        reward = self.rew[act][s]\n",
    "#        n = np.random.choice(numpy.arange(len(self.states)), p = trans)\n",
    "#        self.currentState = self.states[n]\n",
    "#        self.t += 1\n",
    "#        b = (self.t == self.maxStep)\n",
    "#        return(self.currentState, reward, b)\n",
    "#        \"\"\"\n",
    "#        One can act on the environment and obtain its reaction:\n",
    "#        - the new state\n",
    "#        - the reward of the new state\n",
    "#        - should we continue the game?\n",
    "#\n",
    "#        :return: state, reward, game_over\n",
    "#        \"\"\"\n",
    "#\n",
    "#\n",
    "#    def reset(self):\n",
    "#        \"\"\"\n",
    "#        Reinitialize the environment to a random state and returns\n",
    "#        the original state\n",
    "#\n",
    "#        :return: state\n",
    "#        \"\"\"\n",
    "#        s = self.currentState\n",
    "#        n = np.random.choice(numpy.arange(len(self.states)))\n",
    "#        self.currentState = self.states[n]\n",
    "#        self.t = 0\n",
    "#        return(s)\n",
    "#    \n",
    "#    def draw(self, graphic = False):\n",
    "#        if graphic:\n",
    "#            ()\n",
    "#        return(self.currentState)\n",
    "#        \"\"\"\n",
    "#        Visualize in the console or graphically the current state\n",
    "#        \"\"\"\n",
    "#        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
    "\n",
    "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
    "\n",
    "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
    "\n",
    "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trans = [[[.1, .9], [.9, .1]],[[.1, .9], [.9, .1]]]\n",
    "#reward = [[1,2], [2,1]]\n",
    "#test = Environment([1,2],reward,trans,1,5,1)\n",
    "##test.act(1)\n",
    "##test.reset()\n",
    "#test.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, epsilon=0.1, n_action=4):\n",
    "        self.epsilon = epsilon\n",
    "        self.n_action = n_action\n",
    "    \n",
    "    def set_epsilon(self,e):\n",
    "        self.epsilon = e\n",
    "\n",
    "    def act(self,s,train=True):\n",
    "        \"\"\" This function should return the next action to do:\n",
    "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
    "        if train:\n",
    "            if np.random.rand() <= self.epsilon:\n",
    "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
    "            else:\n",
    "                a = self.learned_act(s)\n",
    "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
    "            a = self.learned_act(s)\n",
    "\n",
    "        return a\n",
    "\n",
    "    def learned_act(self,s):\n",
    "        \"\"\" Act via the policy of the agent, from a given state s\n",
    "        it proposes an action a\"\"\"\n",
    "        pass\n",
    "\n",
    "    def reinforce(self, s, n_s, a, r, game_over_):\n",
    "        \"\"\" This function is the core of the learning algorithm. \n",
    "        It takes as an input the current state s_, the next state n_s_\n",
    "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
    "        \n",
    "        Its goal is to learn a policy.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\" This function returns basic stats if applicable: the\n",
    "        loss and/or the model\"\"\"\n",
    "        pass\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\" This function allows to restore a model\"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#class Agent(object):\n",
    "#    def __init__(self, epsilon=0.1, n_action=4):\n",
    "#        self.epsilon = epsilon\n",
    "#        self.n_action = n_action\n",
    "#        self.policy = \n",
    "#    \n",
    "#    def set_epsilon(self,e):\n",
    "#        self.epsilon = e\n",
    "#\n",
    "#    def act(self,s,train=True):\n",
    "#        \"\"\" This function should return the next action to do:\n",
    "#        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
    "#        if train:\n",
    "#            if np.random.rand() <= self.epsilon:\n",
    "#                a = np.random.randint(0, self.n_action, size=1)[0]\n",
    "#            else:\n",
    "#                a = self.learned_act(s)\n",
    "#        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
    "#            a = self.learned_act(s)\n",
    "#\n",
    "#        return a\n",
    "#\n",
    "#    def learned_act(self,s):\n",
    "#        \"\"\" Act via the policy of the agent, from a given state s\n",
    "#        it proposes an action a\"\"\"\n",
    "#        pass\n",
    "#\n",
    "#    def reinforce(self, s, n_s, a, r, game_over_):\n",
    "#        \"\"\" This function is the core of the learning algorithm. \n",
    "#        It takes as an input the current state s_, the next state n_s_\n",
    "#        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
    "#        \n",
    "#        Its goal is to learn a policy.\n",
    "#        \"\"\"\n",
    "#        pass\n",
    "#\n",
    "#    def save(self):\n",
    "#        \"\"\" This function returns basic stats if applicable: the\n",
    "#        loss and/or the model\"\"\"\n",
    "#        pass\n",
    "#\n",
    "#    def load(self):\n",
    "#        \"\"\" This function allows to restore a model\"\"\"\n",
    "#        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 1__:\n",
    "Explain the function act. Why is ```epsilon``` essential?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(you can use Markdown and Latex)\n",
    "The parameter $\\epsilon$ is important because the RL algorithms are based on a trade-off between exploration of the environment and exploitation of the best policy learned so far. The method act realizes this exploration by taking random actions with probability $\\epsilon$ and implements the best policy the rest of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### The Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
    "\n",
    "```python\n",
    "\n",
    "epoch = 300\n",
    "env = Environment()\n",
    "agent = Agent()\n",
    "\n",
    "\n",
    "# Number of won games\n",
    "score = 0\n",
    "loss = 0\n",
    "\n",
    "\n",
    "for e in range(epoch):\n",
    "    # At each epoch, we restart to a fresh game and get the initial state\n",
    "    state = env.reset()\n",
    "    # This assumes that the games will end\n",
    "    game_over = False\n",
    "\n",
    "    win = 0\n",
    "    lose = 0\n",
    "    \n",
    "    while not game_over:\n",
    "        # The agent performs an action\n",
    "        action = agent.act(state)\n",
    "\n",
    "        # Apply an action to the environment, get the next state, the reward\n",
    "        # and if the games end\n",
    "        prev_state = state\n",
    "        state, reward, game_over = env.act(action)\n",
    "\n",
    "        # Update the counters\n",
    "        if reward > 0:\n",
    "            win = win + reward\n",
    "        if reward < 0:\n",
    "            lose = lose -reward\n",
    "\n",
    "        # Apply the reinforcement strategy\n",
    "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "    # Save as a mp4\n",
    "    if e % 10 == 0:\n",
    "        env.draw(e)\n",
    "\n",
    "    # Update stats\n",
    "    score += win-lose\n",
    "\n",
    "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "          .format(e, epoch, loss, win, lose, win-lose))\n",
    "    agent.save()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The game, *eat cheese*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
    "\n",
    "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
    "        grid_size = grid_size+4\n",
    "        self.grid_size = grid_size\n",
    "        self.max_time = max_time\n",
    "        self.temperature = temperature\n",
    "\n",
    "        #board on which one plays\n",
    "        self.board = np.zeros((grid_size,grid_size))\n",
    "        self.position = np.zeros((grid_size,grid_size))\n",
    "\n",
    "        # coordinate of the cat\n",
    "        self.x = 0\n",
    "        self.y = 1\n",
    "\n",
    "        # self time\n",
    "        self.t = 0\n",
    "\n",
    "        self.scale=16\n",
    "\n",
    "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "    def draw(self,e):\n",
    "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
    "\n",
    "    def get_frame(self,t):\n",
    "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
    "        b[self.board>0,0] = 256\n",
    "        b[self.board < 0, 2] = 256\n",
    "        b[self.x,self.y,:]=256\n",
    "        b[-2:,:,:]=0\n",
    "        b[:,-2:,:]=0\n",
    "        b[:2,:,:]=0\n",
    "        b[:,:2,:]=0\n",
    "        \n",
    "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        self.to_draw[t,:,:,:]=b\n",
    "\n",
    "\n",
    "    def act(self, action):\n",
    "        \"\"\"This function returns the new state, reward and decides if the\n",
    "        game ends.\"\"\"\n",
    "\n",
    "        self.get_frame(int(self.t))\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "\n",
    "        self.position[self.x, self.y] = 1\n",
    "        if action == 0:\n",
    "            if self.x == self.grid_size-3:\n",
    "                self.x = self.x-1\n",
    "            else:\n",
    "                self.x = self.x + 1\n",
    "        elif action == 1:\n",
    "            if self.x == 2:\n",
    "                self.x = self.x+1\n",
    "            else:\n",
    "                self.x = self.x-1\n",
    "        elif action == 2:\n",
    "            if self.y == self.grid_size - 3:\n",
    "                self.y = self.y - 1\n",
    "            else:\n",
    "                self.y = self.y + 1\n",
    "        elif action == 3:\n",
    "            if self.y == 2:\n",
    "                self.y = self.y + 1\n",
    "            else:\n",
    "                self.y = self.y - 1\n",
    "        else:\n",
    "            RuntimeError('Error: action not recognized')\n",
    "\n",
    "        self.t = self.t + 1\n",
    "        reward = self.board[self.x, self.y]\n",
    "        self.board[self.x, self.y] = 0\n",
    "        game_over = self.t > self.max_time\n",
    "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
    "\n",
    "        return state, reward, game_over\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
    "\n",
    "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "\n",
    "\n",
    "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
    "\n",
    "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
    "\n",
    "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "        malus[bonus>0]=0\n",
    "\n",
    "        self.board = bonus + malus\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.board[self.x,self.y] = 0\n",
    "        self.t = 0\n",
    "\n",
    "        state = np.concatenate((\n",
    "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "\n",
    "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following elements are important because they correspond to the hyper parameters for this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "size = 13\n",
    "T=200\n",
    "temperature=0.3\n",
    "epochs_train=15 # set small when debugging\n",
    "epochs_test=15 # set small when debugging\n",
    "\n",
    "# display videos\n",
    "def display_videos(name):\n",
    "    video = io.open(name, 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "    return '''<video alt=\"test\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```position``` contains the current state of the agent and the positions that are impossible along the border. ```board``` indicates if there is poison or cheese."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RandomAgent(Agent):\n",
    "    def __init__(self):\n",
    "        super(RandomAgent, self).__init__()\n",
    "        pass\n",
    "\n",
    "    def learned_act(self, s):\n",
    "        return(np.random.choice(self.n_action))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(agent,env,epochs,prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "        \n",
    "    for e in range(epochs):\n",
    "        state = env.reset()\n",
    "        game_over = False\n",
    "        win = 0\n",
    "        lose = 0\n",
    "        while not game_over:\n",
    "            action = agent.act(state)\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action)\n",
    "            if reward > 0:\n",
    "                win += reward\n",
    "            if reward < 0:\n",
    "                lose -= reward\n",
    "        ##### FILL IN HERE\n",
    "        \n",
    "        # Save as a mp4\n",
    "        env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score = score + win-lose\n",
    "\n",
    "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
    "              .format(win, lose, score/(1+e)))\n",
    "    print('Final score: '+str(score/epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win/lose count 12.0/4.0. Average score (8.0)\n",
      "Win/lose count 13.0/14.0. Average score (3.5)\n",
      "Win/lose count 13.5/19.0. Average score (0.5)\n",
      "Win/lose count 8.5/13.0. Average score (-0.75)\n",
      "Win/lose count 9.0/9.0. Average score (-0.6)\n",
      "Win/lose count 9.5/22.0. Average score (-2.5833333333333335)\n",
      "Win/lose count 9.0/12.0. Average score (-2.642857142857143)\n",
      "Win/lose count 11.0/11.0. Average score (-2.3125)\n",
      "Win/lose count 9.0/4.0. Average score (-1.5)\n",
      "Win/lose count 11.0/13.0. Average score (-1.55)\n",
      "Win/lose count 11.0/16.0. Average score (-1.8636363636363635)\n",
      "Win/lose count 10.5/16.0. Average score (-2.1666666666666665)\n",
      "Win/lose count 5.0/10.0. Average score (-2.3846153846153846)\n",
      "Win/lose count 11.0/17.0. Average score (-2.642857142857143)\n",
      "Win/lose count 11.0/17.0. Average score (-2.8666666666666667)\n",
      "Final score: -2.8666666666666667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the game\n",
    "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
    "\n",
    "# Initialize the agent!\n",
    "agent = RandomAgent()\n",
    "\n",
    "test(agent,env,epochs_test,prefix='random')\n",
    "HTML(display_videos('random0.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us assume here that $T=\\infty$.\n",
    "\n",
    "***\n",
    "__Question 5__ Let $\\pi$ be a policy, show that:\n",
    "\n",
    "\\begin{equation*}\n",
    "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
    "\\end{equation*}\n",
    "\n",
    "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
    "\n",
    "\\begin{equation*}\n",
    "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
    "\\end{equation*}\n",
    "Finally, deduce that a plausible objective is:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
    "\\end{equation*}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
    "\n",
    "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
    "\n",
    "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
    "\n",
    "3. Store $(s_t,a_t,s_{t+1})$;\n",
    "\n",
    "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
    "\n",
    "***\n",
    "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "class Memory(object):\n",
    "    def __init__(self, max_memory=100):\n",
    "        self.max_memory = max_memory\n",
    "        self.memory = list()\n",
    "\n",
    "    def remember(self, m):\n",
    "        if len(self.memory)>=self.max_memory:\n",
    "            _ = self.memory.pop()\n",
    "        self.memory.append(m)\n",
    "\n",
    "    def random_access(self):\n",
    "        return random.choice(self.memory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "The pipeline we will use for training is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(agent,env,epoch,prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "    loss = 0\n",
    "\n",
    "    for e in range(epoch):\n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will terminate\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "\n",
    "        while not game_over:\n",
    "            # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "\n",
    "            # Apply the reinforcement strategy\n",
    "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "        # Save as a mp4\n",
    "        if e % 10 == 0:\n",
    "            env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score += win-lose\n",
    "\n",
    "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "              .format(e, epoch, loss, win, lose, win-lose))\n",
    "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DQN(Agent):\n",
    "    def __init__(self, grid_size,  epsilon = 0.1, memory_size=100, batch_size = 16,n_state=2):\n",
    "        super(DQN, self).__init__(epsilon = epsilon)\n",
    "\n",
    "        # Discount for Q learning\n",
    "        self.discount = 0.99\n",
    "        \n",
    "        self.grid_size = grid_size\n",
    "        \n",
    "        # number of state\n",
    "        self.n_state = n_state\n",
    "\n",
    "        # Memory\n",
    "        self.memory = Memory(memory_size)\n",
    "        \n",
    "        # Batch size when learning\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def learned_act(self, s):\n",
    "        pass\n",
    "\n",
    "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
    "        # Two steps: first memorize the states, second learn from the pool\n",
    "\n",
    "        self.memory.remember([s_, n_s_, a_, r_, game_over_])\n",
    "        \n",
    "        input_states = np.zeros((self.batch_size, 5,5,self.n_state))\n",
    "        target_q = np.zeros((self.batch_size, 4))\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            ######## FILL IN\n",
    "            s_, n_s_, a_, r_, game_over_ = self.memory.random_access()\n",
    "            input_states[i] = s_\n",
    "            if game_over_:\n",
    "                Qf = np.zeros(4)\n",
    "            else:\n",
    "                Qf = self.model.predict(n_s_[None])[0]\n",
    "            #print(Qf)\n",
    "            target_q[i][a_] = r_ + self.discount * np.max(Qf) # size 4 ??\n",
    "            #print(np.max(Qf))\n",
    "                \n",
    "        ######## FILL IN target q and input states\n",
    "        # HINT: Clip the target to avoid exploding gradients.. -- clipping is a bit tighter\n",
    "        target_q = np.clip(target_q, -3, 3)\n",
    "        l = self.model.train_on_batch(input_states, target_q)\n",
    "        return l\n",
    "\n",
    "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
    "        self.model.save_weights(name_weights, overwrite=True)\n",
    "        with open(name_model, \"w\") as outfile:\n",
    "            json.dump(self.model.to_json(), outfile)\n",
    "            \n",
    "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
    "        with open(name_model, \"r\") as jfile:\n",
    "            model = model_from_json(json.load(jfile))\n",
    "        model.load_weights(name_weights)\n",
    "        model.compile(\"sgd\", \"mse\")\n",
    "        self.model = model\n",
    "\n",
    "            \n",
    "class DQN_FC(DQN):\n",
    "    def __init__(self, *args, lr=0.1,**kwargs):\n",
    "        super(DQN_FC, self).__init__( *args,**kwargs)\n",
    "        \n",
    "        # NN Model\n",
    "        \n",
    "        ####### FILL IN\n",
    "        model = Sequential()\n",
    "        model.add(Dense(64, input_shape = (5, 5, 2), activation = 'relu'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(32, activation = 'relu'))\n",
    "        model.add(Dense(4, activation = 'softmax'))\n",
    "        \n",
    "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
    "        self.model = model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000/015 | Loss 0.0108 | Win/lose count 3.0/1.0 (2.0)\n",
      "Epoch 001/015 | Loss 0.0174 | Win/lose count 1.5/3.0 (-1.5)\n",
      "Epoch 002/015 | Loss 0.0094 | Win/lose count 1.5/5.0 (-3.5)\n",
      "Epoch 003/015 | Loss 0.0134 | Win/lose count 2.5/5.0 (-2.5)\n",
      "Epoch 004/015 | Loss 0.0145 | Win/lose count 3.5/3.0 (0.5)\n",
      "Epoch 005/015 | Loss 0.0105 | Win/lose count 1.5/3.0 (-1.5)\n",
      "Epoch 006/015 | Loss 0.0122 | Win/lose count 1.5/1.0 (0.5)\n",
      "Epoch 007/015 | Loss 0.0134 | Win/lose count 3.0/2.0 (1.0)\n",
      "Epoch 008/015 | Loss 0.0224 | Win/lose count 3.0/4.0 (-1.0)\n",
      "Epoch 009/015 | Loss 0.0179 | Win/lose count 1.0/2.0 (-1.0)\n",
      "Epoch 010/015 | Loss 0.0061 | Win/lose count 1.5/1.0 (0.5)\n",
      "Epoch 011/015 | Loss 0.0029 | Win/lose count 1.0/2.0 (-1.0)\n",
      "Epoch 012/015 | Loss 0.0077 | Win/lose count 0.5/4.0 (-3.5)\n",
      "Epoch 013/015 | Loss 0.0036 | Win/lose count 0.5/3.0 (-2.5)\n",
      "Epoch 014/015 | Loss 0.0080 | Win/lose count 1.5/0 (1.5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAEy5tZGF0AAACnwYF//+b3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1MiAtIEguMjY0L01QRUctNCBBVkMgY29kZWMgLSBDb3B5bGVmdCAyMDAzLTIwMTcgLSBodHRwOi8vd3d3LnZpZGVvbGFuLm9yZy94MjY0Lmh0bWwgLSBvcHRpb25zOiBjYWJhYz0xIHJlZj0zIGRlYmxvY2s9MTowOjAgYW5hbHlzZT0weDE6MHgxMTEgbWU9aGV4IHN1Ym1lPTcgcHN5PTEgcHN5X3JkPTEuMDA6MC4wMCBtaXhlZF9yZWY9MSBtZV9yYW5nZT0xNiBjaHJvbWFfbWU9MSB0cmVsbGlzPTEgOHg4ZGN0PTAgY3FtPTAgZGVhZHpvbmU9MjEsMTEgZmFzdF9wc2tpcD0xIGNocm9tYV9xcF9vZmZzZXQ9NCB0aHJlYWRzPTggbG9va2FoZWFkX3RocmVhZHM9MSBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRlcmxhY2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJfcHlyYW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9MCB3ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTI1IHNjZW5lY3V0PTQwIGludHJhX3JlZnJlc2g9MCByY19sb29rYWhlYWQ9NDAgcmM9Y3JmIG1idHJlZT0xIGNyZj0yMy4wIHFjb21wPTAuNjAgcXBtaW49MCBxcG1heD02OSBxcHN0ZXA9NCBpcF9yYXRpbz0xLjQwIGFxPTE6MS4wMACAAAAClWWIhAA7//72/PwKbVMJ/y2f/oi/5W/vT9mutbhROzO0GnMD0Av93Hf14tWwq3Nuy3HRvGyZAFN0aIn/Ia774FKKpH4FM1rE8w2YRh2xHhrcKPt+JwHs/BedtRiHaTlcjcMq41xwWFBPyNPQxM9KU9ebzuScZZWxvvC07mfrwTQ0qo8VHUpZhxS7L0bsIG5Oi+wREKJHvncIrlDv6cgrrLpbT6r/WNIho1FKhBrJtNHrMK7uONAQOla15z8kNOzogbLvv5+Wydp1g/lbnZyHgyIYgXUzYnXANc7wigalp5dGuOKr406/A30N/YeXBMzTTffoJm2BIUvUR8QRTns6NHqLLlfvEyh4MMR/Xpkk64qVw8DLexcxCyvN9FhQizNXXUxcAtXfWnW8mSlADwYr0sVQpE8zNWraKn0c10pwkbhKWOKUVvSsHgxmHshK66wA8wbkVEiVQb6a40FqI2BlqHWXaKqMHhBSFRtIOCiAClS9Dsm0CIDbK0uN3zNvz+ULxFiY1fFW+btHIKfTxIt1CzlFBut39SHaROj/3nGUj9HB6eUr8uRpy9WH1zDxbqS0VdBkK5SW4xxUC5iSXIQLzvIu1QjjKKph0HWrMrB4fC+2YoCSTvON8v2g0CseeWwb9HPpgZcK7Thrn86M3515hYktkzGy5uvjbHoV9K64pClQ971ut9AI0Sqj4MZRW5b4QK5WPGUNnNmdegxrTMU+AjUxSBo9CFJWeRpqyrddJD4G0YfdeyUB9Y8gXdCIA1IBOVqZaIRlApRbVgmP3+QEQHI5XeJwMBxHywhw3OKSQnYqJPry1KvFq5QAAD0DtwoNRWW/ZnehFIkWiCVviG+OojlQlVQ4dRKPUPR/RNRYz4Nk4zAAj4EAAAANQZokbEO//qmWAACVgAAAAApBnkJ4hf8AALKBAAAACgGeYXRCvwAA7oAAAAAKAZ5jakK/AADugQAAABNBmmhJqEFomUwId//+qZYAAJWBAAAADEGehkURLC//AACygQAAAAoBnqV0Qr8AAO6BAAAACgGep2pCvwAA7oAAAAAbQZqqSahBbJlMFEw7//6plgAHdHT8S8hKQ008AAAADQGeyWpCvwAMQRoHBMEAAAAYQZrOSeEKUmUwId/+qZYAB3UyEkGIbTTwAAAAD0Ge7EU0TC//AAjs9a7WYAAAAA0Bnwt0Qr8ADD/8v0ExAAAACgGfDWpCvwAA7oEAAAATQZsSSahBaJlMCHf//qmWAACVgQAAAAxBnzBFESwv/wAAsoAAAAAKAZ9PdEK/AADugAAAAAoBn1FqQr8AAO6BAAAAGkGbVkmoQWyZTAh3//6plgAHdHT8S8hKQ008AAAAD0GfdEUVLC//AAjs9a7WYAAAAA0Bn5N0Qr8ADESJhQPhAAAACgGflWpCvwAA7oAAAAAYQZuaSahBbJlMCHf//qmWAAd1qTThaaeBAAAAD0GfuEUVLC//AAjs9a7WYQAAAA0Bn9d0Qr8ADD/8v0EwAAAACgGf2WpCvwAA7oEAAAATQZveSahBbJlMCHf//qmWAACVgAAAAAxBn/xFFSwv/wAAsoEAAAAKAZ4bdEK/AADugQAAAAoBnh1qQr8AAO6AAAAAE0GaAkmoQWyZTAh3//6plgAAlYAAAAAMQZ4gRRUsL/8AALKBAAAACgGeX3RCvwAA7oAAAAAKAZ5BakK/AADugQAAABNBmkZJqEFsmUwId//+qZYAAJWAAAAADEGeZEUVLC//AACygQAAAAoBnoN0Qr8AAO6BAAAACgGehWpCvwAA7oEAAAATQZqKSahBbJlMCHf//qmWAACVgQAAAAxBnqhFFSwv/wAAsoAAAAAKAZ7HdEK/AADugAAAAAoBnslqQr8AAO6BAAAAE0GazkmoQWyZTAh3//6plgAAlYAAAAAMQZ7sRRUsL/8AALKAAAAACgGfC3RCvwAA7oEAAAAKAZ8NakK/AADugQAAABNBmxJJqEFsmUwId//+qZYAAJWBAAAADEGfMEUVLC//AACygAAAAAoBn090Qr8AAO6AAAAACgGfUWpCvwAA7oEAAAATQZtWSahBbJlMCHf//qmWAACVgAAAAAxBn3RFFSwv/wAAsoAAAAAKAZ+TdEK/AADugQAAAAoBn5VqQr8AAO6AAAAAGkGbmkmoQWyZTAh3//6plgAHU+FGVWZtmDrhAAAAD0GfuEUVLC//AAiuedmkpQAAAAoBn9d0Qr8AAO6AAAAADQGf2WpCvwAL863nwbEAAAATQZveSahBbJlMCHf//qmWAACVgAAAAAxBn/xFFSwv/wAAsoEAAAAKAZ4bdEK/AADugQAAAAoBnh1qQr8AAO6AAAAAE0GaAkmoQWyZTAh3//6plgAAlYAAAAAMQZ4gRRUsL/8AALKBAAAACgGeX3RCvwAA7oAAAAAKAZ5BakK/AADugQAAABNBmkZJqEFsmUwId//+qZYAAJWAAAAADEGeZEUVLC//AACygQAAAAoBnoN0Qr8AAO6BAAAACgGehWpCvwAA7oEAAAAaQZqKSahBbJlMCHf//qmWAAsohwk3Dgo+b/kAAAAPQZ6oRRUsL/8ADTKtSs3YAAAACgGex3RCvwAA7oAAAAANAZ7JakK/ABHdnm4jsQAAABNBms5JqEFsmUwId//+qZYAAJWAAAAADEGe7EUVLC//AACygAAAAAoBnwt0Qr8AAO6BAAAACgGfDWpCvwAA7oEAAAATQZsSSahBbJlMCHf//qmWAACVgQAAAAxBnzBFFSwv/wAAsoAAAAAKAZ9PdEK/AADugAAAAAoBn1FqQr8AAO6BAAAAE0GbVkmoQWyZTAh3//6plgAAlYAAAAAMQZ90RRUsL/8AALKAAAAACgGfk3RCvwAA7oEAAAAKAZ+VakK/AADugAAAABNBm5pJqEFsmUwId//+qZYAAJWBAAAADEGfuEUVLC//AACygQAAAAoBn9d0Qr8AAO6AAAAACgGf2WpCvwAA7oEAAAATQZveSahBbJlMCHf//qmWAACVgAAAAAxBn/xFFSwv/wAAsoEAAAAKAZ4bdEK/AADugQAAAAoBnh1qQr8AAO6AAAAAE0GaAkmoQWyZTAh3//6plgAAlYAAAAAMQZ4gRRUsL/8AALKBAAAACgGeX3RCvwAA7oAAAAAKAZ5BakK/AADugQAAABNBmkZJqEFsmUwId//+qZYAAJWAAAAADEGeZEUVLC//AACygQAAAAoBnoN0Qr8AAO6BAAAACgGehWpCvwAA7oEAAAATQZqKSahBbJlMCHf//qmWAACVgQAAAAxBnqhFFSwv/wAAsoAAAAAKAZ7HdEK/AADugAAAAAoBnslqQr8AAO6BAAAAE0GazkmoQWyZTAh3//6plgAAlYAAAAAMQZ7sRRUsL/8AALKAAAAACgGfC3RCvwAA7oEAAAAKAZ8NakK/AADugQAAABpBmxJJqEFsmUwId//+qZYAC26WVmeQlIaXtQAAAA9BnzBFFSwv/wANgHogG9AAAAANAZ9PdEK/ABJfMrTnoAAAAAoBn1FqQr8AAO6BAAAAE0GbVkmoQWyZTAh3//6plgAAlYAAAAAMQZ90RRUsL/8AALKAAAAACgGfk3RCvwAA7oEAAAAKAZ+VakK/AADugAAAABtBm5hJqEFsmUwUTDv//qmWABGEWG6KTO+7ZHEAAAANAZ+3akK/ABxQf81g4QAAABhBm7xJ4QpSZTAh3/6plgASAo50qW7kZcAAAAAPQZ/aRTRML/8AFZY25YTRAAAADQGf+XRCvwAc/hF+aXAAAAAKAZ/7akK/AADugQAAABNBm+BJqEFomUwId//+qZYAAJWBAAAADEGeHkURLC//AACygAAAAAoBnj10Qr8AAO6AAAAACgGeP2pCvwAA7oEAAAAaQZokSahBbJlMCHf//qmWABIfjz9+yDcVGeAAAAAPQZ5CRRUsL/8AFZoBblP1AAAACgGeYXRCvwAA7oAAAAANAZ5jakK/AB0GeFzX6QAAABNBmmhJqEFsmUwId//+qZYAAJWBAAAADEGehkUVLC//AACygQAAAAoBnqV0Qr8AAO6BAAAACgGep2pCvwAA7oAAAAATQZqsSahBbJlMCHf//qmWAACVgAAAAAxBnspFFSwv/wAAsoEAAAAKAZ7pdEK/AADugAAAAAoBnutqQr8AAO6AAAAAGkGa8EmoQWyZTAh3//6plgALx76sqszbMErBAAAAD0GfDkUVLC//AA3QeiAbMQAAAA0Bny10Qr8AEtdP/nMxAAAACgGfL2pCvwAA7oAAAAATQZs0SahBbJlMCHf//qmWAACVgAAAAAxBn1JFFSwv/wAAsoEAAAAKAZ9xdEK/AADugAAAAAoBn3NqQr8AAO6AAAAAE0GbeEmoQWyZTAh3//6plgAAlYEAAAAMQZ+WRRUsL/8AALKAAAAACgGftXRCvwAA7oEAAAAKAZ+3akK/AADugQAAABNBm7xJqEFsmUwId//+qZYAAJWAAAAADEGf2kUVLC//AACygQAAAAoBn/l0Qr8AAO6AAAAACgGf+2pCvwAA7oEAAAATQZvgSahBbJlMCHf//qmWAACVgQAAAAxBnh5FFSwv/wAAsoAAAAAKAZ49dEK/AADugAAAAAoBnj9qQr8AAO6BAAAAGkGaJEmoQWyZTAh3//6plgARhFhujEI59hrgAAAAD0GeQkUVLC//ABUGUltWoQAAAA0BnmF0Qr8AHE4nrdtQAAAACgGeY2pCvwAA7oEAAAATQZpoSahBbJlMCHf//qmWAACVgQAAAAxBnoZFFSwv/wAAsoEAAAAKAZ6ldEK/AADugQAAAAoBnqdqQr8AAO6AAAAAE0GarEmoQWyZTAh3//6plgAAlYAAAAAMQZ7KRRUsL/8AALKBAAAACgGe6XRCvwAA7oAAAAAKAZ7rakK/AADugAAAABNBmvBJqEFsmUwId//+qZYAAJWBAAAADEGfDkUVLC//AACygQAAAAoBny10Qr8AAO6BAAAACgGfL2pCvwAA7oAAAAAaQZs0SahBbJlMCHf//qmWABGfo59+yDcVGuAAAAAPQZ9SRRUsL/8AFQoBblQdAAAACgGfcXRCvwAA7oAAAAANAZ9zakK/ABxWeFzYOAAAABpBm3hJqEFsmUwId//+qZYAC3++r67EG4qXMQAAAA9Bn5ZFFSwv/wANgq1KzZgAAAAKAZ+1dEK/AADugQAAAA0Bn7dqQr8AEllcCYFBAAAAE0GbvEmoQWyZTAh3//6plgAAlYAAAAAMQZ/aRRUsL/8AALKBAAAACgGf+XRCvwAA7oAAAAAKAZ/7akK/AADugQAAABpBm+BJqEFsmUwIb//+p4QADtA8KdZ0+66OgQAAAA9Bnh5FFSwv/wAI7PWu1mAAAAANAZ49dEK/AAxEiYUD4AAAAAoBnj9qQr8AAO6BAAAAEkGaJEmoQWyZTAhv//6nhAABJwAAAAxBnkJFFSwv/wAAsoEAAAAKAZ5hdEK/AADugAAAAAoBnmNqQr8AAO6BAAAAEkGaaEmoQWyZTAhf//6MsAAEjQAAAAxBnoZFFSwv/wAAsoEAAAAKAZ6ldEK/AADugQAAAAoBnqdqQr8AAO6AAAAAGkGaqUuoQhBbJEYIKAfyAf2HgCFf/jhAABFwAAAMiG1vb3YAAABsbXZoZAAAAAAAAAAAAAAAAAAAA+gAAB+QAAEAAAEAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAIAAAuydHJhawAAAFx0a2hkAAAAAwAAAAAAAAAAAAAAAQAAAAAAAB+QAAAAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAQAAAAAEQAAABEAAAAAAAJGVkdHMAAAAcZWxzdAAAAAAAAAABAAAfkAAABAAAAQAAAAALKm1kaWEAAAAgbWRoZAAAAAAAAAAAAAAAAAAAMgAAAZQAVcQAAAAAAC1oZGxyAAAAAAAAAAB2aWRlAAAAAAAAAAAAAAAAVmlkZW9IYW5kbGVyAAAACtVtaW5mAAAAFHZtaGQAAAABAAAAAAAAAAAAAAAkZGluZgAAABxkcmVmAAAAAAAAAAEAAAAMdXJsIAAAAAEAAAqVc3RibAAAAJVzdHNkAAAAAAAAAAEAAACFYXZjMQAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAEQARAASAAAAEgAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABj//wAAAC9hdmNDAfQADf/hABdn9AANkZsoIhHQgAAAAwCAAAAZB4oUywEABWjr48RIAAAAGHN0dHMAAAAAAAAAAQAAAMoAAAIAAAAAFHN0c3MAAAAAAAAAAQAAAAEAAAZgY3R0cwAAAAAAAADKAAAAAQAABAAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABgAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAYAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAACgAAAAABAAAEAAAAAAEAAAAAAAAAAQAAAgAAAAABAAAKAAAAAAEAAAQAAAAAAQAAAAAAAAABAAACAAAAAAEAAAoAAAAAAQAABAAAAAABAAAAAAAAAAEAAAIAAAAAAQAABAAAAAAcc3RzYwAAAAAAAAABAAAAAQAAAMoAAAABAAADPHN0c3oAAAAAAAAAAAAAAMoAAAU8AAAAEQAAAA4AAAAOAAAADgAAABcAAAAQAAAADgAAAA4AAAAfAAAAEQAAABwAAAATAAAAEQAAAA4AAAAXAAAAEAAAAA4AAAAOAAAAHgAAABMAAAARAAAADgAAABwAAAATAAAAEQAAAA4AAAAXAAAAEAAAAA4AAAAOAAAAFwAAABAAAAAOAAAADgAAABcAAAAQAAAADgAAAA4AAAAXAAAAEAAAAA4AAAAOAAAAFwAAABAAAAAOAAAADgAAABcAAAAQAAAADgAAAA4AAAAXAAAAEAAAAA4AAAAOAAAAHgAAABMAAAAOAAAAEQAAABcAAAAQAAAADgAAAA4AAAAXAAAAEAAAAA4AAAAOAAAAFwAAABAAAAAOAAAADgAAAB4AAAATAAAADgAAABEAAAAXAAAAEAAAAA4AAAAOAAAAFwAAABAAAAAOAAAADgAAABcAAAAQAAAADgAAAA4AAAAXAAAAEAAAAA4AAAAOAAAAFwAAABAAAAAOAAAADgAAABcAAAAQAAAADgAAAA4AAAAXAAAAEAAAAA4AAAAOAAAAFwAAABAAAAAOAAAADgAAABcAAAAQAAAADgAAAA4AAAAeAAAAEwAAABEAAAAOAAAAFwAAABAAAAAOAAAADgAAAB8AAAARAAAAHAAAABMAAAARAAAADgAAABcAAAAQAAAADgAAAA4AAAAeAAAAEwAAAA4AAAARAAAAFwAAABAAAAAOAAAADgAAABcAAAAQAAAADgAAAA4AAAAeAAAAEwAAABEAAAAOAAAAFwAAABAAAAAOAAAADgAAABcAAAAQAAAADgAAAA4AAAAXAAAAEAAAAA4AAAAOAAAAFwAAABAAAAAOAAAADgAAAB4AAAATAAAAEQAAAA4AAAAXAAAAEAAAAA4AAAAOAAAAFwAAABAAAAAOAAAADgAAABcAAAAQAAAADgAAAA4AAAAeAAAAEwAAAA4AAAARAAAAHgAAABMAAAAOAAAAEQAAABcAAAAQAAAADgAAAA4AAAAeAAAAEwAAABEAAAAOAAAAFgAAABAAAAAOAAAADgAAABYAAAAQAAAADgAAAA4AAAAeAAAAFHN0Y28AAAAAAAAAAQAAADAAAABidWR0YQAAAFptZXRhAAAAAAAAACFoZGxyAAAAAAAAAABtZGlyYXBwbAAAAAAAAAAAAAAAAC1pbHN0AAAAJal0b28AAAAdZGF0YQAAAAEAAAAATGF2ZjU4LjIwLjEwMA==\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "train(agent, env, epochs_train, prefix='fc_train')\n",
    "HTML(display_videos('fc_train10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DQN_CNN(DQN):\n",
    "    def __init__(self, *args,lr=0.1,**kwargs):\n",
    "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
    "        \n",
    "        ###### FILL IN\n",
    "        \n",
    "        model = Sequential()\n",
    "        #model.add(Reshape((5, 5), input_shape = (5, 5, 2)))\n",
    "        model.add(Conv2D(32, (3, 3), input_shape = (5, 5, 2), activation = 'relu')) # channels last\n",
    "        model.add(Conv2D(16, (2, 2), activation = 'relu'))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(32, activation = 'relu'))\n",
    "        model.add(Dense(4, activation = 'softmax'))\n",
    "        \n",
    "        \n",
    "        # Conv2D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization\n",
    "        model.compile(sgd(lr=lr, momentum=0.0, decay=1e-4), \"mse\") # \n",
    "        self.model = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000/015 | Loss 0.0142 | Win/lose count 2.0/2.0 (0.0)\n",
      "Epoch 001/015 | Loss 0.0084 | Win/lose count 1.5/4.0 (-2.5)\n",
      "Epoch 002/015 | Loss 0.0260 | Win/lose count 2.5/4.0 (-1.5)\n",
      "Epoch 003/015 | Loss 0.0044 | Win/lose count 1.5/6.0 (-4.5)\n",
      "Epoch 004/015 | Loss 0.0069 | Win/lose count 1.0/4.0 (-3.0)\n",
      "Epoch 005/015 | Loss 0.0035 | Win/lose count 1.0/1.0 (0.0)\n",
      "Epoch 006/015 | Loss 0.0067 | Win/lose count 1.0/0 (1.0)\n",
      "Epoch 007/015 | Loss 0.0184 | Win/lose count 2.0/3.0 (-1.0)\n",
      "Epoch 008/015 | Loss 0.0164 | Win/lose count 1.0/3.0 (-2.0)\n",
      "Epoch 009/015 | Loss 0.0116 | Win/lose count 1.0/1.0 (0.0)\n",
      "Epoch 010/015 | Loss 0.0219 | Win/lose count 1.5/3.0 (-1.5)\n",
      "Epoch 011/015 | Loss 0.0068 | Win/lose count 3.0/3.0 (0.0)\n",
      "Epoch 012/015 | Loss 0.0059 | Win/lose count 2.0/2.0 (0.0)\n",
      "Epoch 013/015 | Loss 0.0045 | Win/lose count 2.5/0 (2.5)\n",
      "Epoch 014/015 | Loss 0.0122 | Win/lose count 1.0/2.0 (-1.0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "train(agent,env,epochs_train,prefix='cnn_train')\n",
    "HTML(display_videos('cnn_train10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test of the CNN\n",
      "Win/lose count 1.0/4.0. Average score (-3.0)\n",
      "Win/lose count 3.5/2.0. Average score (-0.75)\n",
      "Win/lose count 1.5/0. Average score (0.0)\n",
      "Win/lose count 0/2.0. Average score (-0.5)\n",
      "Win/lose count 1.0/1.0. Average score (-0.4)\n",
      "Win/lose count 1.5/2.0. Average score (-0.4166666666666667)\n",
      "Win/lose count 1.0/1.0. Average score (-0.35714285714285715)\n",
      "Win/lose count 3.0/2.0. Average score (-0.1875)\n",
      "Win/lose count 1.5/3.0. Average score (-0.3333333333333333)\n",
      "Win/lose count 1.5/4.0. Average score (-0.55)\n",
      "Win/lose count 2.5/2.0. Average score (-0.45454545454545453)\n",
      "Win/lose count 3.0/1.0. Average score (-0.25)\n",
      "Win/lose count 0.5/5.0. Average score (-0.5769230769230769)\n",
      "Win/lose count 1.5/5.0. Average score (-0.7857142857142857)\n",
      "Win/lose count 1.5/2.0. Average score (-0.7666666666666667)\n",
      "Final score: -0.7666666666666667\n",
      "Test of the FC\n",
      "Win/lose count 3.0/1.0. Average score (2.0)\n",
      "Win/lose count 1.0/1.0. Average score (1.0)\n",
      "Win/lose count 1.5/5.0. Average score (-0.5)\n",
      "Win/lose count 2.5/1.0. Average score (0.0)\n",
      "Win/lose count 1.5/5.0. Average score (-0.7)\n",
      "Win/lose count 1.0/1.0. Average score (-0.5833333333333334)\n",
      "Win/lose count 0/3.0. Average score (-0.9285714285714286)\n",
      "Win/lose count 0.5/1.0. Average score (-0.875)\n",
      "Win/lose count 1.5/4.0. Average score (-1.0555555555555556)\n",
      "Win/lose count 1.0/1.0. Average score (-0.95)\n",
      "Win/lose count 1.0/7.0. Average score (-1.4090909090909092)\n",
      "Win/lose count 1.5/2.0. Average score (-1.3333333333333333)\n",
      "Win/lose count 1.0/1.0. Average score (-1.2307692307692308)\n",
      "Win/lose count 0.5/1.0. Average score (-1.1785714285714286)\n",
      "Win/lose count 3.5/3.0. Average score (-1.0666666666666667)\n",
      "Final score: -1.0666666666666667\n"
     ]
    }
   ],
   "source": [
    "env = Environment(grid_size=size, max_time=T,temperature=0.3)\n",
    "agent_cnn = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "agent_cnn.load(name_weights='cnn_trainmodel.h5',name_model='cnn_trainmodel.json')\n",
    "\n",
    "agent_fc = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "agent_cnn.load(name_weights='fc_trainmodel.h5',name_model='fc_trainmodel.json')\n",
    "print('Test of the CNN')\n",
    "test(agent_cnn,env,epochs_test,prefix='cnn_test')\n",
    "print('Test of the FC')\n",
    "test(agent_fc,env,epochs_test,prefix='fc_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(display_videos('cnn_test10.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(display_videos('fc_test10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
    "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
    "2. Append via the environment a new state that describes if a cell has been visited or not\n",
    "\n",
    "***\n",
    "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_explore(agent,env,epoch,prefix=''):\n",
    "    \n",
    "    ## use those samples of code:\n",
    "    #In train explore:\n",
    "    #state, reward, game_over = env.act(action, train=True)\n",
    "    \n",
    "    \n",
    "    # Number of won games\n",
    "    score = 0\n",
    "    loss = 0\n",
    "\n",
    "    for e in range(epoch):\n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will terminate\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "        \n",
    "        agent.set_epsilon(agent.epsilon * 0.95) # decrease the parameter epsilon at each epoch\n",
    "\n",
    "        while not game_over:\n",
    "            # The agent performs an action (epsilon greedy)\n",
    "            action = agent.act(state, train=True)\n",
    "            \n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action, train = True)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "\n",
    "            # Apply the reinforcement strategy\n",
    "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "        # Save as a mp4\n",
    "        if e % 10 == 0:\n",
    "            env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score += win-lose\n",
    "\n",
    "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "              .format(e, epoch, loss, win, lose, win-lose))\n",
    "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "class EnvironmentExploring(object):\n",
    "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
    "        grid_size = grid_size+4\n",
    "        self.grid_size = grid_size\n",
    "        self.max_time = max_time\n",
    "        self.temperature = temperature\n",
    "\n",
    "        #board on which one plays\n",
    "        self.board = np.zeros((grid_size,grid_size))\n",
    "        self.position = np.zeros((grid_size,grid_size))\n",
    "        self.malus_position = np.zeros((grid_size,grid_size)) # another board to store the malus\n",
    "\n",
    "        # coordinate of the cat (rat?)\n",
    "        self.x = 0\n",
    "        self.y = 1\n",
    "\n",
    "        # self time\n",
    "        self.t = 0\n",
    "\n",
    "        self.scale=16\n",
    "\n",
    "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "    def draw(self,e):\n",
    "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
    "\n",
    "    def get_frame(self,t):\n",
    "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
    "        b[self.board>0,0] = 256\n",
    "        b[self.board < 0, 2] = 256\n",
    "        b[self.x,self.y,:]=256 # rat in black?\n",
    "        b[-2:,:,:]=0\n",
    "        b[:,-2:,:]=0\n",
    "        b[:2,:,:]=0\n",
    "        b[:,:2,:]=0\n",
    "        # forbidden borders in white?\n",
    "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        self.to_draw[t,:,:,:]=b\n",
    "\n",
    "\n",
    "    def act(self, action, train = False):\n",
    "        \"\"\"This function returns the new state, reward and decides if the\n",
    "        game ends.\"\"\"\n",
    "        \n",
    "        self.get_frame(int(self.t))\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "\n",
    "        self.position[self.x, self.y] = 1\n",
    "        if action == 0:\n",
    "            if self.x == self.grid_size-3:\n",
    "                self.x = self.x-1\n",
    "            else:\n",
    "                self.x = self.x + 1\n",
    "        elif action == 1:\n",
    "            if self.x == 2:\n",
    "                self.x = self.x+1\n",
    "            else:\n",
    "                self.x = self.x-1\n",
    "        elif action == 2:\n",
    "            if self.y == self.grid_size - 3:\n",
    "                self.y = self.y - 1\n",
    "            else:\n",
    "                self.y = self.y + 1\n",
    "        elif action == 3:\n",
    "            if self.y == 2:\n",
    "                self.y = self.y + 1\n",
    "            else:\n",
    "                self.y = self.y - 1\n",
    "        else:\n",
    "            RuntimeError('Error: action not recognized')\n",
    "\n",
    "        self.t = self.t + 1\n",
    "        \n",
    "        #reward = self.board[self.x, self.y]\n",
    "        # this line is replaced by the following block\n",
    "        reward = 0\n",
    "        if train: # dont apply it if in test\n",
    "            reward = -self.malus_position[self.x, self.y]\n",
    "        self.malus_position[self.x, self.y] = 0.3 #0.1\n",
    "        reward = reward + self.board[self.x, self.y]\n",
    "\n",
    "        self.board[self.x, self.y] = 0\n",
    "        game_over = self.t > self.max_time\n",
    "        \n",
    "        # 3 \"feature\" states instead of 2\n",
    "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
    "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "        \n",
    "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
    "\n",
    "        return state, reward, game_over\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
    "\n",
    "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "\n",
    "\n",
    "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2) # in fact bernoulli\n",
    "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
    "\n",
    "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
    "\n",
    "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "        malus[bonus>0]=0\n",
    "\n",
    "        self.board = bonus + malus\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.board[self.x,self.y] = 0\n",
    "        self.t = 0\n",
    "\n",
    "        # 3 \"feature\" states instead of 2\n",
    "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
    "                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "        \n",
    "\n",
    "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
    "        return state\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We change our CNN model to fit the right input\n",
    "\n",
    "from keras import backend as K\n",
    "keras.backend.set_learning_phase(1)\n",
    "\n",
    "class DQN_CNN(DQN):\n",
    "    def __init__(self, *args,lr=0.1,**kwargs):\n",
    "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
    "        \n",
    "        ###### FILL IN\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, (3, 3), input_shape = (5, 5, 3), activation = 'relu')) # channels last\n",
    "        model.add(Dropout(.15))\n",
    "        model.add(Conv2D(16, (2, 2), activation = 'relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(32, activation = 'relu'))\n",
    "        model.add(Dense(4, activation = 'softmax'))\n",
    "        \n",
    "        \n",
    "        #model.add(BatchNormalization())\n",
    "        #model.add(Dropout(.25))\n",
    "        #model.add(AveragePooling2D())\n",
    "        \n",
    "        # Conv2D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization\n",
    "        model.compile(sgd(lr=lr, momentum=0.0, decay=1e-4), \"mse\") # \n",
    "        self.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000/015 | Loss 0.0817 | Win/lose count 1.5/58.999999999999815 (-57.499999999999815)\n",
      "Epoch 001/015 | Loss 0.0706 | Win/lose count 1.5/59.0999999999998 (-57.5999999999998)\n",
      "Epoch 002/015 | Loss 0.0688 | Win/lose count 1.5/60.199999999999804 (-58.699999999999804)\n",
      "Epoch 003/015 | Loss 0.0729 | Win/lose count 0.5/58.89999999999981 (-58.39999999999981)\n",
      "Epoch 004/015 | Loss 0.0726 | Win/lose count 2.5/57.89999999999981 (-55.39999999999981)\n",
      "Epoch 005/015 | Loss 0.0732 | Win/lose count 0.8/58.999999999999794 (-58.1999999999998)\n",
      "Epoch 006/015 | Loss 0.0732 | Win/lose count 3.0/57.39999999999982 (-54.39999999999982)\n",
      "Epoch 007/015 | Loss 0.0827 | Win/lose count 2.9000000000000004/61.09999999999979 (-58.19999999999979)\n",
      "Epoch 008/015 | Loss 0.0746 | Win/lose count 1.2/59.099999999999795 (-57.89999999999979)\n",
      "Epoch 009/015 | Loss 0.0871 | Win/lose count 1.7/59.59999999999979 (-57.899999999999785)\n",
      "Epoch 010/015 | Loss 0.0867 | Win/lose count 1.0/59.099999999999795 (-58.099999999999795)\n",
      "Epoch 011/015 | Loss 0.0793 | Win/lose count 0.4/59.4999999999998 (-59.0999999999998)\n",
      "Epoch 012/015 | Loss 0.0814 | Win/lose count 0.4/59.6999999999998 (-59.2999999999998)\n",
      "Epoch 013/015 | Loss 0.0791 | Win/lose count 0.7/61.49999999999978 (-60.79999999999978)\n",
      "Epoch 014/015 | Loss 0.0829 | Win/lose count 0.2/59.79999999999979 (-59.59999999999979)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32,n_state=3)\n",
    "train_explore(agent, env, epochs_train, prefix='cnn_train_explore')\n",
    "HTML(display_videos('cnn_train_explore10.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win/lose count 1.5/0. Average score (1.5)\n",
      "Win/lose count 1.0/1.0. Average score (0.75)\n",
      "Win/lose count 0.5/1.0. Average score (0.3333333333333333)\n",
      "Win/lose count 1.5/1.0. Average score (0.375)\n",
      "Win/lose count 1.0/1.0. Average score (0.3)\n",
      "Win/lose count 2.0/1.0. Average score (0.4166666666666667)\n",
      "Win/lose count 1.5/3.0. Average score (0.14285714285714285)\n",
      "Win/lose count 1.0/3.0. Average score (-0.125)\n",
      "Win/lose count 0.5/3.0. Average score (-0.3888888888888889)\n",
      "Win/lose count 1.0/1.0. Average score (-0.35)\n",
      "Win/lose count 1.0/2.0. Average score (-0.4090909090909091)\n",
      "Win/lose count 1.0/0. Average score (-0.2916666666666667)\n",
      "Win/lose count 2.5/1.0. Average score (-0.15384615384615385)\n",
      "Win/lose count 1.5/0. Average score (-0.03571428571428571)\n",
      "Win/lose count 0.5/3.0. Average score (-0.2)\n",
      "Final score: -0.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation\n",
    "test(agent,env,epochs_test,prefix='cnn_test_explore')\n",
    "HTML(display_videos('cnn_test_explore10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
